{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5a3363",
   "metadata": {},
   "source": [
    "# Video Indexer Transcript Analysis with Langchain + AOAI + Azure AI Search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d35c6a",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "\n",
    "- Korkrid Kyle Akepanidtaworn, AI Specialized CSA, Global Customer Success\n",
    "- Serge Retkowsky, AI GBB, Microsoft France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae81f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain) (0.3.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_community in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (0.3.51)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (0.3.23)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (3.11.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (0.3.31)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tenacity in c:\\users\\koakepan\\downloads\\azure-ai-video-indexer-samples\\.venv\\lib\\site-packages (9.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "%pip install langchain\n",
    "%pip install langchain_community\n",
    "%pip install -qU langchain-openai\n",
    "%pip install --upgrade --quiet  azure-search-documents\n",
    "%pip install --upgrade --quiet  azure-identity\n",
    "%pip install tqdm\n",
    "%pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c90537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n",
      "Python executable: c:\\Users\\koakepan\\Downloads\\Azure-AI-Video-Indexer-Samples\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import time  # For execution time tracking\n",
    "import json # For JSON handling\n",
    "import re # For regular expressions\n",
    "import requests # For making HTTP requests\n",
    "import sys # To interact with the Python runtime environment\n",
    "from dotenv import dotenv_values # For loading environment variables from .env file\n",
    "from dotenv import load_dotenv # For loading environment variables from .env file\n",
    "from pprint import pprint # For pretty-printing JSON\n",
    "import getpass # For secure password input\n",
    "from tqdm import tqdm # For progress bar in loops\n",
    "\n",
    "# Import the required libraries for Azure AI VIdeo Indexer\n",
    "from VideoIndexerClient.Consts import Consts\n",
    "from VideoIndexerClient.VideoIndexerClient import VideoIndexerClient\n",
    "\n",
    "# Import the required libraries for Azure Blob Storage and OpenAI\n",
    "import os\n",
    "import base64\n",
    "from openai import AzureOpenAI  # Interface for interacting with Azure-hosted OpenAI services\n",
    "\n",
    "# Import LangChain components for building conversational AI and working with documents\n",
    "from langchain.chat_models import AzureChatOpenAI  # OpenAI's Azure-based chat models for conversation\n",
    "from langchain_openai import AzureOpenAI # OpenAI's Azure-based models for text generation\n",
    "from langchain.chains import RetrievalQA  # For building a QA pipeline with retrieval capabilities\n",
    "from langchain.retrievers import AzureCognitiveSearchRetriever  # Retriever using Azure Cognitive Search\n",
    "from langchain.prompts import PromptTemplate  # Template for formatting prompts to AI models\n",
    "from langchain.document_loaders import TextLoader  # For loading documents (e.g., text files)\n",
    "from langchain.text_splitter import CharacterTextSplitter  # For splitting text into smaller chunks for processing\n",
    "from langchain.vectorstores import AzureSearch  # For storing and searching embeddings in Azure Search\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch # For storing and searching embeddings in Azure Search\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings # Azure-specific OpenAI embeddings\n",
    "\n",
    "# Load environment variables from the specified .env file\n",
    "# This allows sensitive keys and endpoints to be managed securely outside the code\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# Print Python version to confirm environment compatibility\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validate the environment variables for Azure OpenAI (Optional)\n",
    "# print(os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\").split(\",\"))  # Print the Azure OpenAI deployment name for confirmation\n",
    "# print(os.getenv(\"AZURE_OPENAI_ENDPOINT\").split(\",\"))  # Print the Azure OpenAI endpoint for confirmation\n",
    "# print(os.getenv(\"AZURE_OPENAI_KEY\").split(\",\"))  # Print the Azure OpenAI key for confirmation\n",
    "# print(os.getenv(\"AZURE_OPENAI_API_VERSION\").split(\",\"))  # print the Azure OpenAI API version for confirmation\n",
    "# print(os.getenv(\"AZURE_COGNITIVE_SEARCH_ENDPOINT\"))  # Print the Azure Cognitive Search endpoint for confirmation\n",
    "# print(os.getenv(\"AZURE_COGNITIVE_SEARCH_API_KEY\"))  # Print the Azure Cognitive Search key for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249832e",
   "metadata": {},
   "source": [
    "# Document Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11227909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saint_Gobain_2023.csv\n",
      "St_Gobain_materials.csv\n",
      "Total number of documents: 4\n",
      "First document: page_content='﻿0,8493325710296631;00:00:02.080;00:00:06.295;2022 aura été décidément une année pleine de bouleversements, entre\n",
      "0,8493325710296631;00:00:06.358;00:00:10.258;le dérèglement climatique, la flambée des prix de l'énergie et\n",
      "0,8493325710296631;00:00:10.321;00:00:14.788;le retour de l'inflation dans cet environnement chahuté, Saint-Gobain à\n",
      "0,8493325710296631;00:00:14.851;00:00:18.248;garder le cap et signé une nouvelle fois des résultats\n",
      "0,8493325710296631;00:00:18.311;00:00:21.834;records ou tous les indicateurs de performance sont à la\n",
      "0,8493325710296631;00:00:21.897;00:00:26.678;hausse. Des résultats qui valident l'efficacité de notre modèle opérationnel\n",
      "0,8493325710296631;00:00:26.741;00:00:30.830;par pays pour s'adapter rapidement aux évolutions de nos marchés.\n",
      "0,8493325710296631;00:00:30.893;00:00:34.920;Cette année 2022 aura été marquée par des réalisations majeures.\n",
      "0,7321534156799316;00:00:35.620;00:00:40.687;Nous avons poursuivi le rééquilibrage de notre empreinte géographique entre\n",
      "0,7321534156799316;00:00:40.754;00:00:44.943;Europe, Amérique, Asie et pays émergents. Nous avons réalisé 2\n",
      "0,7321534156799316;00:00:45.011;00:00:49.808;mouvements clés avec l'acquisition de kaikan au Canada et l'intégration\n",
      "0,7321534156799316;00:00:49.876;00:00:54.403;de dissipe apply technologies, acteur mondial majeur dans la chimie\n",
      "0,7321534156799316;00:00:54.470;00:00:59.065;de la construction. Avec les acquisitions récentes de chriso dissipe\n",
      "0,7321534156799316;00:00:59.132;00:01:02.713;impact au Mexique, bras prefer et match EM au Brésil,\n",
      "0,7321534156799316;00:01:02.781;00:01:07.105;idi Picnics en Égypte, Saint-Gobain devient un leader mondial du\n",
      "0,7321534156799316;00:01:07.172;00:01:09.470;marché, très dynamique et porteur.\n",
      "0,8591077923774719;00:01:09.570;00:01:10.990;De la chimie de la construction.\n",
      "0,8120883703231812;00:01:11.760;00:01:15.111;En ligne avec nos objectifs, nous avons aussi cédé en\n",
      "0,8120883703231812;00:01:15.174;00:01:19.157;2022 la distribution au Royaume-Uni et en Pologne des activités\n",
      "0,8120883703231812;00:01:19.221;00:01:23.141;dans la transformation verrière et celles dans les cristaux et\n",
      "0,8120883703231812;00:01:23.204;00:01:23.900;détecteurs.\n",
      "0,874867856502533;00:01:24.990;00:01:29.778;Nous avons également investi dans de nouvelles capacités industrielles. Le\n",
      "0,874867856502533;00:01:29.843;00:01:33.207;groupe a ainsi ouvert en 2022 18 nouvelles usines et\n",
      "0,874867856502533;00:01:33.272;00:01:37.672;lignes de production pour renforcer ses positions. 2022. C'est aussi\n",
      "0,874867856502533;00:01:37.737;00:01:41.943;pour le groupe une année de réalisation emblématique partout dans\n",
      "0,874867856502533;00:01:42.008;00:01:45.696;le monde, de l'Amérique à l'Asie en passant par l'Europe.\n",
      "0,874867856502533;00:01:45.761;00:01:49.255;Tout cela, nous l'avons fait dans le respect absolu de\n",
      "0,874867856502533;00:01:49.320;00:01:54.626;notre responsabilité sociale et environnementale, avec comme mot d'ordre maximiser\n",
      "0,874867856502533;00:01:54.691;00:01:56.049;notre impact positif.\n",
      "0,8389058113098145;00:01:56.410;00:02:01.184;En réduisant notre empreinte sur l'environnement. Bilan, nous avons notamment\n",
      "0,8389058113098145;00:02:01.246;00:02:04.408;déployé en 2022 la première offre au monde de verre\n",
      "0,8389058113098145;00:02:04.470;00:02:08.190;bas carbone ainsi que la première plaque de plâtre fabriquée\n",
      "0,8389058113098145;00:02:08.252;00:02:11.166;à partir de plus de 50% de plâtres recyclés. Et\n",
      "0,8389058113098145;00:02:11.228;00:02:14.639;pour relever ces défis, nous nous sommes appuyés sur la\n",
      "0,8389058113098145;00:02:14.701;00:02:18.917;force de notre innovation en réalisant des premières mondiales comme\n",
      "0,8389058113098145;00:02:18.979;00:02:21.645;la production 0 carbone en scope un et 2 de\n",
      "0,8389058113098145;00:02:21.707;00:02:24.559;verres à aniche, dans le nord de la France, et\n",
      "0,8389058113098145;00:02:24.621;00:02:28.589;une production très bas carbone dans l'isolation laine de verre.' metadata={'source': 'transcripts\\\\Saint_Gobain_2023.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Document directory\n",
    "DOCS_DIR = \"transcripts\"\n",
    "\n",
    "# Loop through the folders\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(DOCS_DIR):\n",
    "    for file in filenames:\n",
    "        print(file)\n",
    "        try:\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding=\"utf-8\")\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "# Split into chunk of texts\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "print(f\"Total number of documents: {len(texts)}\")  # Print the total number of documents loaded\n",
    "# Print the first document for inspection   \n",
    "print(f\"First document: {texts[0]}\")  # Print the first document for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53555d9",
   "metadata": {},
   "source": [
    "## Embeddings and Loading the Documents into the Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3433ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model: client=<openai.resources.embeddings.Embeddings object at 0x0000028837875940> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000002883787F800> model='text-embedding-ada-002' dimensions=None deployment='text-embedding-ada-002' openai_api_version='2023-05-15' openai_api_base=None openai_api_type='azure' openai_proxy=None embedding_ctx_length=8191 openai_api_key=SecretStr('**********') openai_organization=None allowed_special=None disallowed_special=None chunk_size=1 max_retries=2 request_timeout=None headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None http_async_client=None check_embedding_ctx_length=True azure_endpoint='https://devaoai1234.openai.azure.com/' azure_ad_token=None azure_ad_token_provider=None azure_ad_async_token_provider=None validate_base_url=True\n",
      "Embedding model type: <class 'langchain_openai.embeddings.azure.AzureOpenAIEmbeddings'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# Initialize the OpenAI embeddings model using Azure settings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=os.getenv(\"AZURE_ADA_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    model=os.getenv(\"AZURE_ADA_EMBEDDING_MODEL_NAME\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    chunk_size=1,\n",
    ")\n",
    "\n",
    "print(f\"Embedding model: {embeddings}\")  # Print the embedding model details for verification\n",
    "print(f\"Embedding model type: {type(embeddings)}\")  # Print the type of the embedding model for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "458f30a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index name: videoindexer-transcripts\n",
      "Azure AI Search instance initialized.\n"
     ]
    }
   ],
   "source": [
    "# Specify the index name for Azure AI Search\n",
    "index_name = os.getenv(\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\")\n",
    "print(f\"Index name: {index_name}\")  # Print the index name for reference\n",
    "\n",
    "# Initialize our Azure AI Search instance\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_COGNITIVE_SEARCH_ENDPOINT\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_COGNITIVE_SEARCH_API_KEY\"),\n",
    "    index_name = index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")\n",
    "print(\"Azure AI Search instance initialized.\")  # Print confirmation of Azure Search initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d35efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding documents to Azure AI Search: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All documents added to Azure AI Search.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add documents to Azure AI Search with TQDM progress tracking\n",
    "for text in tqdm(texts, desc=\"Adding documents to Azure AI Search\"):\n",
    "    try:\n",
    "        vector_store.add_documents(documents=[text])\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding document: {e}\")\n",
    "print(\"All documents added to Azure AI Search.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f89445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever initialized.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Azure Cognitive Search retriever for document retrieval\n",
    "retriever = AzureAISearchRetriever(\n",
    "    # 'content_key' specifies the field in the search index containing the document content\n",
    "    content_key=\"content\",  # The field in the Azure Cognitive Search index that holds document content\n",
    "    \n",
    "    # 'top_k' specifies how many of the top matching documents to retrieve from the index\n",
    "    top_k=10,  # Retrieve the top 10 documents that match the search query\n",
    "    \n",
    "    # 'index_name' refers to the name of the search index in Azure Cognitive Search\n",
    "    index_name = index_name,  # The name of the index to query in Azure Cognitive Search\n",
    "\n",
    "    # 'service_name' specifies the name of the Azure Cognitive Search service\n",
    "    service_name = os.getenv(\"AZURE_AI_SEARCH_SERVICE_NAME\"),  # The name of the Azure AI Search service\n",
    "    api_key =  os.getenv(\"AZURE_COGNITIVE_SEARCH_API_KEY\"),  # The API key for authenticating with the Azure AI Search service\n",
    ")\n",
    "\n",
    "# Preview the retriever's configuration\n",
    "# print(f\"Retriever configuration: {retriever.__dict__}\")  # Print the retriever's configuration for debugging\n",
    "print(\"Retriever initialized.\")  # Print confirmation of retriever initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b04985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM configuration: {'name': None, 'cache': None, 'verbose': False, 'callbacks': None, 'tags': None, 'metadata': None, 'custom_get_token_ids': None, 'callback_manager': None, 'rate_limiter': None, 'disable_streaming': False, 'client': <openai.resources.chat.completions.completions.Completions object at 0x00000288388ABE30>, 'async_client': <openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002883898C3B0>, 'root_client': <openai.lib.azure.AzureOpenAI object at 0x00000288388A86B0>, 'root_async_client': <openai.lib.azure.AsyncAzureOpenAI object at 0x00000288388ABDA0>, 'model_name': None, 'temperature': 0.7, 'model_kwargs': {}, 'openai_api_key': SecretStr('**********'), 'openai_api_base': None, 'openai_organization': None, 'openai_proxy': None, 'request_timeout': None, 'stream_usage': False, 'max_retries': None, 'presence_penalty': None, 'frequency_penalty': None, 'seed': None, 'logprobs': None, 'top_logprobs': None, 'logit_bias': None, 'streaming': False, 'n': None, 'top_p': None, 'max_tokens': None, 'reasoning_effort': None, 'tiktoken_model_name': None, 'default_headers': None, 'default_query': None, 'http_client': None, 'http_async_client': None, 'stop': None, 'extra_body': None, 'include_response_headers': False, 'disabled_params': {'parallel_tool_calls': None}, 'use_responses_api': None, 'azure_endpoint': 'https://devaoai1234.openai.azure.com/', 'deployment_name': 'gpt-4o', 'openai_api_version': '2025-01-01-preview', 'azure_ad_token': None, 'azure_ad_token_provider': None, 'azure_ad_async_token_provider': None, 'model_version': '', 'openai_api_type': 'azure', 'validate_base_url': True}\n",
      "LLM initialized.\n"
     ]
    }
   ],
   "source": [
    "# Azure OpenAI has several chat models. You can find information about their latest models and their costs, context windows, and supported input types in the Azure docs.\n",
    "# API Reference: https://python.langchain.com/docs/integrations/chat/azure_chat_openai/\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(azure_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "                      api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "                      api_key = os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "                      temperature=0.7)\n",
    "\n",
    "# Preview the LLM's configuration\n",
    "print(f\"LLM configuration: {llm.__dict__}\")  # Print the LLM's configuration for debugging\n",
    "print(\"LLM initialized.\")  # Print confirmation of LLM initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11189e3f",
   "metadata": {},
   "source": [
    "# Video Transcript Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf92fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template message\n",
    "template = \"\"\"You are analyzing a transcript text file that contains the speech to text results from a video file. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Set the Retrieval QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411a416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koakepan\\AppData\\Local\\Temp\\ipykernel_8668\\1278630149.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34m\n",
      "Question: Could you summarize in a couple of lines the document Saint_Gobain_2023.csv?\n",
      "\u001b[1;31;32m\n",
      "Answer: The document \"Saint_Gobain_2023.csv\" is a transcript of speeches highlighting Saint-Gobain's achievements and innovations in 2022 and plans for 2023. It emphasizes the company's advancements in manufacturing, environmental sustainability, and social responsibility, including the development of low-carbon products and global recognition for gender equality and top employer certification.\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Could you summarize in a couple of lines the document Saint_Gobain_2023.csv?\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    #chat_history.append((question, result))\n",
    "    print(\"\\033[1;31;34m\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"\\033[1;31;32m\")\n",
    "    print(f\"Answer: {result['result']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5143eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34m\n",
      "Question: Can you generate 10 keywords from Saint_Gobain_2023.csv?\n",
      "\u001b[1;31;32m\n",
      "Answer: To generate 10 keywords from the provided transcript, we should look for recurring themes, significant terms, and core ideas presented in the text. Here are 10 keywords based on the content:\n",
      "\n",
      "1. Saint-Gobain\n",
      "2. Innovation\n",
      "3. Carbon Neutrality\n",
      "4. Sustainability\n",
      "5. Global Expansion\n",
      "6. Performance\n",
      "7. Decarbonization\n",
      "8. Manufacturing\n",
      "9. Leadership\n",
      "10. Environmental Responsibility\n",
      "\n",
      "These keywords reflect the main topics and themes discussed in the transcript, highlighting Saint-Gobain's focus on innovation, sustainability, and global market leadership.\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Can you generate 10 keywords from Saint_Gobain_2023.csv?\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    #chat_history.append((question, result))\n",
    "    print(\"\\033[1;31;34m\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"\\033[1;31;32m\")\n",
    "    print(f\"Answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b3018d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34m\n",
      "Question: You are a twitter redactor. Write a tweeter post about the content of Saint_Gobain_materials.csv?Use some smileys\n",
      "\u001b[1;31;32m\n",
      "Answer: 🌟 Exciting developments at Saint-Gobain! 🌟 In 2022, we saw groundbreaking innovations, including the launch of low-carbon glass and eco-friendly plasterboard made from recycled materials. 🌍 Our continuous commitment to sustainability and excellence has set new records, with 18 new factories and production lines opened worldwide. Congrats to the team for earning the Global Top Employer certification! 💼👏 Let's make 2023 another year of success and innovation in the construction industry! 🚀 #Sustainability #Innovation #SaintGobain #TopEmployer\n"
     ]
    }
   ],
   "source": [
    "questions = [\"You are a twitter redactor. Write a tweeter post about the content of Saint_Gobain_materials.csv?\\\n",
    "Use some smileys\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    #chat_history.append((question, result))\n",
    "    print(\"\\033[1;31;34m\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"\\033[1;31;32m\")\n",
    "    print(f\"Answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01bea8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34m\n",
      "Question: Display the timeframe of the curing of glass process in the St_Gobain.csv file? Just print the values              like a json file\n",
      "\u001b[1;31;32m\n",
      "Answer: ```json\n",
      "{\n",
      "  \"start_time\": \"00:02:52.826\",\n",
      "  \"end_time\": \"00:02:56.400\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Display the timeframe of the curing of glass process in the St_Gobain.csv file? Just print the values \\\n",
    "             like a json file\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    #chat_history.append((question, result))\n",
    "    print(\"\\033[1;31;34m\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"\\033[1;31;32m\")\n",
    "    print(f\"Answer: {result['result']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
